{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQTdAeI3Rl1P"
      },
      "source": [
        "# Mapping CVE entries to MITRE ATT&CK Framework "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9x0xsPakltr"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjG7YveRRxiu"
      },
      "outputs": [],
      "source": [
        "! pip install transformers\n",
        "! rm -rf /content/*\n",
        "! wget https://attack.mitre.org/docs/enterprise-attack-v13.1/enterprise-attack-v13.1-techniques.xlsx\n",
        "! mv /content/enterprise-attack-v13.1-techniques.xlsx /content/enterprise-techniques.xlsx\n",
        "! gdown 105bU7r9ICrYGJ8CWdrq2gQ3BGxej2yYc\n",
        "! gdown 1mYLUQNI3jRGkABVCwFvhx95QcX6YOkEL\n",
        "! gdown 1-snCfXjRyGh_Kuu_QKAPhTEEa_Wt-BHH\n",
        "! gdown 1lmCSmhS2h1EdQznMX-HuxHSkkkF0Yo0g\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igmXhuZBRvxc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tga7a3_RxgM"
      },
      "outputs": [],
      "source": [
        "enterpriseTechniquesDF = pd.read_excel(\"/content/enterprise-techniques.xlsx\")\n",
        "cveDF = pd.read_csv(\"/content/cve.csv\")\n",
        "cveDF.rename(columns={\"Unnamed: 0\" : \"CVE\"}, inplace=True)\n",
        "enterpriseTechniquesDF.dropna(axis=0, how=\"any\", subset=[\"description\"], inplace=True)\n",
        "cveDF.dropna(axis=0, how=\"any\", subset=[\"summary\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_mask):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "\n",
        "    def __len__(self):\n",
        "        assert len(self.input_ids)==len(self.attention_mask)\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attention_mask[idx]\n"
      ],
      "metadata": {
        "id": "M69VPNG0sKKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingHelper:\n",
        "    def __init__(self, device=\"cpu\", model_path=\"ehsanaghaei/SecureBERT\", batch_size=16):\n",
        "        self.device = device\n",
        "        self.cpu = \"cpu\"\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = AutoModel.from_pretrained(model_path)\n",
        "\n",
        "    def GenerateEmbeddings(self, inputs):\n",
        "        numBatches:int = int(len(inputs) / self.batch_size)\n",
        "        if(len(inputs) % self.batch_size!=0):\n",
        "            numBatches += 1\n",
        "\n",
        "        input_ids = []\n",
        "        attention_mask = []\n",
        "        for batch in tqdm(range(numBatches)):\n",
        "            encoding = self.tokenizer.batch_encode_plus(inputs[batch * self.batch_size : (batch+1) * self.batch_size],\n",
        "                                                        add_special_tokens=False,          \n",
        "                                                        max_length=128,\n",
        "                                                        truncation=True, \n",
        "                                                        padding=\"max_length\",\n",
        "                                                        return_attention_mask=True,\n",
        "                                                        return_tensors=\"pt\")\n",
        "            \n",
        "            input_ids += encoding[\"input_ids\"]\n",
        "            attention_mask += encoding[\"attention_mask\"]\n",
        "\n",
        "        dataset = EmbeddingDataset(input_ids, attention_mask)\n",
        "        dataloader = DataLoader(dataset,\n",
        "                                batch_size=self.batch_size,\n",
        "                                shuffle=False)\n",
        "\n",
        "        outputEmbedding = []\n",
        "        self.model.to(self.device).eval()\n",
        "\n",
        "        for index, (input_ids, attention_mask) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "            input_ids = input_ids.to(self.device)\n",
        "            attention_mask = attention_mask.to(self.device)\n",
        "\n",
        "            sampleEmbedding = torch.mean(self.model(input_ids, attention_mask)[0], 1).to(self.cpu)\n",
        "            for x in sampleEmbedding:\n",
        "                outputEmbedding.append(x)\n",
        "        \n",
        "        return outputEmbedding"
      ],
      "metadata": {
        "id": "oUwJN8ARLUkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_val = 42\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_path = \"ehsanaghaei/SecureBERT\"\n",
        "batch_size = 16\n",
        "\n",
        "helper = EmbeddingHelper(device=device,\n",
        "                         model_path=model_path,\n",
        "                         batch_size=batch_size)\n",
        "\n",
        "enterpriseTechniqueDescriptions = enterpriseTechniquesDF[\"description\"].values.tolist()\n",
        "enterpriseTechniqueEmbeddings = helper.GenerateEmbeddings(enterpriseTechniqueDescriptions)\n",
        "enterpriseTechniquesDF[\"embeddings\"] = enterpriseTechniqueEmbeddings\n",
        "\n",
        "cveDescriptions = cveDF[\"summary\"].values.tolist()\n",
        "cveEmbeddings = helper.GenerateEmbeddings(cveDescriptions)\n",
        "cveDF[\"embeddings\"] = cveEmbeddings"
      ],
      "metadata": {
        "id": "Is3JsX4qb0Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to low memory, had to split the data into three parts and generate embeddings separately"
      ],
      "metadata": {
        "id": "HMJ3rVAvcwmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb1 = np.load(\"/content/emb1.npy\")\n",
        "emb2 = np.load(\"/content/emb2.npy\")\n",
        "emb3 = np.load(\"/content/emb3.npy\")"
      ],
      "metadata": {
        "id": "HkYD9cMUcjM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb1 = np.append(np.append(emb1, emb2, axis=0), emb3, axis=0)"
      ],
      "metadata": {
        "id": "pxa6BwxkfSBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cveSummary = cveDF[\"summary\"].values.tolist()"
      ],
      "metadata": {
        "id": "RXonU5PmXRcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"ehsanaghaei/SecureBERT\")\n",
        "model = AutoModel.from_pretrained(\"ehsanaghaei/SecureBERT\")"
      ],
      "metadata": {
        "id": "xeKGwmwBXj9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed(sample):\n",
        "    encoding = tokenizer.encode_plus(sample,\n",
        "                                add_special_tokens=False,          \n",
        "                                max_length=128,\n",
        "                                truncation=True, \n",
        "                                padding=\"max_length\",\n",
        "                                return_attention_mask=True,\n",
        "                                return_tensors=\"pt\")\n",
        "    sample_embedding = torch.mean(model(**encoding)[0], 1)\n",
        "    return sample_embedding"
      ],
      "metadata": {
        "id": "jI4aQDyPiSLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CosineSimilarity = nn.CosineSimilarity(dim = 0)"
      ],
      "metadata": {
        "id": "1FhVTV58c_uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mitre = []\n",
        "mitre_sim = []\n",
        "for j in tqdm(range(len(cveDF))):   \n",
        "    cve_sample_embedding = embed(cveSummary[j]).detach().numpy()[0]\n",
        "    max_idx = 0\n",
        "    max_sim = -1\n",
        "    for i in range(607):\n",
        "        sim = CosineSimilarity(torch.tensor(emb1[i]), torch.tensor(cve_sample_embedding))\n",
        "        if(sim > max_sim):\n",
        "            max_sim = sim\n",
        "            max_idx = i\n",
        "    mitre.append(max_idx)\n",
        "    mitre_sim.append(max_sim)"
      ],
      "metadata": {
        "id": "Eb7_TnzugEG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "    print(\"Sample\", i)\n",
        "    print(cveDF[\"CVE\"].values[i])\n",
        "    print(cveSummary[i])\n",
        "    print()\n",
        "    print(enterpriseTechniquesDF[\"description\"].values[mitre[i]])\n",
        "    print()\n",
        "    print(mitre_sim[i])\n",
        "    print()\n",
        "    print(\"-\" * 100)"
      ],
      "metadata": {
        "id": "Jp7m9A0myq8J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}